{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a074b358-951a-4d7e-9853-7043611122f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conne\\anaconda3\\envs\\datascience\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:22: UserWarning: Pandas requires version '2.10.2' or newer of 'numexpr' (version '2.8.7' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5c3a98-b26b-4668-93be-739c30a2c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 files with shape (2830743, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conne\\AppData\\Local\\Temp\\ipykernel_29344\\996074344.py:10: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  for col in df.select_dtypes(include=\"object\").columns:\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(r\"C:\\Users\\conne\\Documents\\Csci-Capstone\\Data\\CIC-IDS2017\")\n",
    "csv_files = list(data_path.glob(\"*.csv\"))\n",
    "\n",
    "df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "print(f\"Loaded {len(csv_files)} files with shape {df.shape}\")\n",
    "\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df = df.loc[:, df.isna().mean() < 0.3]\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=\"number\").columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_cols = [\n",
    "    \"fwd_header_length.1\",\n",
    "    \"fwd_avg_bytes/bulk\",\"fwd_avg_packets/bulk\",\"fwd_avg_bulk_rate\",\n",
    "    \"bwd_avg_bytes/bulk\",\"bwd_avg_packets/bulk\",\"bwd_avg_bulk_rate\"\n",
    "]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78806350-40f4-4abe-b26b-1b0194550f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means ROC-AUC: 0.7155701784030799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kmeans_dropped_features.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Layered IDS: K-Means (Behavioral Deviation Scoring)\n",
    "# -------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Extract numeric features\n",
    "# -------------------------------\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "if 'label' in numeric_features:\n",
    "    numeric_features.remove('label')\n",
    "\n",
    "X_unsup = df[numeric_features]\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Remove highly correlated features\n",
    "# (MUST match Isolation Forest)\n",
    "# -------------------------------\n",
    "corr_matrix = X_unsup.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "to_drop = [col for col in upper.columns if any(upper[col] > 0.9)]\n",
    "X_unsup_clean = X_unsup.drop(columns=to_drop)\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Scale features\n",
    "# -------------------------------\n",
    "feature_scaler = StandardScaler()\n",
    "X_scaled = feature_scaler.fit_transform(X_unsup_clean)\n",
    "\n",
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Train / validation split\n",
    "# (labels ONLY for evaluation)\n",
    "# -------------------------------\n",
    "y_eval = df['label'].apply(lambda x: 0 if x.lower() == 'benign' else 1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled,\n",
    "    y_eval,\n",
    "    test_size=0.2,\n",
    "    stratify=y_eval,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ Train K-Means\n",
    "# -------------------------------\n",
    "# k chosen to represent common traffic behaviors\n",
    "kmeans = KMeans(\n",
    "    n_clusters=8,\n",
    "    init=\"k-means++\",\n",
    "    n_init=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# -------------------------------\n",
    "# 6Ô∏è‚É£ Distance-based anomaly scoring\n",
    "# -------------------------------\n",
    "# Distance to closest centroid = behavioral deviation\n",
    "train_distances = np.min(\n",
    "    kmeans.transform(X_train), axis=1\n",
    ")\n",
    "\n",
    "val_distances = np.min(\n",
    "    kmeans.transform(X_val), axis=1\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 7Ô∏è‚É£ Normalize scores for ensemble fusion\n",
    "# -------------------------------\n",
    "score_scaler = MinMaxScaler()\n",
    "\n",
    "train_scores_norm = score_scaler.fit_transform(\n",
    "    train_distances.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "val_scores_norm = score_scaler.transform(\n",
    "    val_distances.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "# -------------------------------\n",
    "# 8Ô∏è‚É£ Define risk tiers (NO hard classification)\n",
    "# -------------------------------\n",
    "LOW_RISK = np.percentile(train_scores_norm, 75)\n",
    "MEDIUM_RISK = np.percentile(train_scores_norm, 90)\n",
    "HIGH_RISK = np.percentile(train_scores_norm, 97)\n",
    "\n",
    "def kmeans_risk_label(score):\n",
    "    if score >= HIGH_RISK:\n",
    "        return \"high\"\n",
    "    elif score >= MEDIUM_RISK:\n",
    "        return \"medium\"\n",
    "    elif score >= LOW_RISK:\n",
    "        return \"low\"\n",
    "    else:\n",
    "        return \"normal\"\n",
    "\n",
    "risk_labels_val = [kmeans_risk_label(s) for s in val_scores_norm]\n",
    "\n",
    "# -------------------------------\n",
    "# 9Ô∏è‚É£ Offline evaluation only\n",
    "# -------------------------------\n",
    "print(\"K-Means ROC-AUC:\",\n",
    "      roc_auc_score(y_val, val_scores_norm))\n",
    "\n",
    "# -------------------------------\n",
    "# üîü Save artifacts for downstream layers\n",
    "# -------------------------------\n",
    "joblib.dump(kmeans, \"kmeans_model.pkl\")\n",
    "joblib.dump(feature_scaler, \"kmeans_feature_scaler.pkl\")\n",
    "joblib.dump(score_scaler, \"kmeans_score_scaler.pkl\")\n",
    "joblib.dump(to_drop, \"kmeans_dropped_features.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d4cb8-be9b-44b4-8579-fff580869fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
