{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a16021e-9bd5-4448-b7a1-63f635eb33db",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f937fcb-88aa-498c-87cc-331404acec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84635d4c-9a6f-4760-9518-1647365eb556",
   "metadata": {},
   "source": [
    "### Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08120afa-9a72-4a34-918e-fe925cdbe151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 files with shape (2830743, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conne\\AppData\\Local\\Temp\\ipykernel_4820\\996074344.py:10: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  for col in df.select_dtypes(include=\"object\").columns:\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(r\"C:\\Users\\conne\\Documents\\Csci-Capstone\\Data\\CIC-IDS2017\")\n",
    "csv_files = list(data_path.glob(\"*.csv\"))\n",
    "\n",
    "df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "print(f\"Loaded {len(csv_files)} files with shape {df.shape}\")\n",
    "\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df = df.loc[:, df.isna().mean() < 0.3]\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=\"number\").columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_cols = [\n",
    "    \"fwd_header_length.1\",\n",
    "    \"fwd_avg_bytes/bulk\",\"fwd_avg_packets/bulk\",\"fwd_avg_bulk_rate\",\n",
    "    \"bwd_avg_bytes/bulk\",\"bwd_avg_packets/bulk\",\"bwd_avg_bulk_rate\"\n",
    "]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0318d23d-d563-4d6c-a523-4243ff745140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest ROC-AUC: 0.6518532530579756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['iso_dropped_features.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Layered IDS: Isolation Forest (Anomaly Scoring Only)\n",
    "# -------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Extract numeric features\n",
    "# -------------------------------\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove label if present\n",
    "if 'label' in numeric_features:\n",
    "    numeric_features.remove('label')\n",
    "\n",
    "X_unsup = df[numeric_features]\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Remove highly correlated features\n",
    "# -------------------------------\n",
    "corr_matrix = X_unsup.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "to_drop = [col for col in upper.columns if any(upper[col] > 0.9)]\n",
    "X_unsup_clean = X_unsup.drop(columns=to_drop)\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Scale features\n",
    "# -------------------------------\n",
    "feature_scaler = StandardScaler()\n",
    "X_scaled = feature_scaler.fit_transform(X_unsup_clean)\n",
    "\n",
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Train / validation split\n",
    "# (labels ONLY for offline evaluation)\n",
    "# -------------------------------\n",
    "y_eval = df['label'].apply(lambda x: 0 if x.lower() == 'benign' else 1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled,\n",
    "    y_eval,\n",
    "    test_size=0.2,\n",
    "    stratify=y_eval,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ Train Isolation Forest\n",
    "# -------------------------------\n",
    "iso = IsolationForest(\n",
    "    n_estimators=200,\n",
    "    max_samples='auto',\n",
    "    contamination=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "iso.fit(X_train)\n",
    "\n",
    "# -------------------------------\n",
    "# 6Ô∏è‚É£ Generate anomaly scores\n",
    "# (higher = more anomalous)\n",
    "# -------------------------------\n",
    "train_scores = -iso.score_samples(X_train)\n",
    "val_scores = -iso.score_samples(X_val)\n",
    "\n",
    "# -------------------------------\n",
    "# 7Ô∏è‚É£ Normalize scores for ensemble fusion\n",
    "# -------------------------------\n",
    "score_scaler = MinMaxScaler()\n",
    "\n",
    "train_scores_norm = score_scaler.fit_transform(\n",
    "    train_scores.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "val_scores_norm = score_scaler.transform(\n",
    "    val_scores.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "# -------------------------------\n",
    "# 8Ô∏è‚É£ Define risk tiers (NO hard classification)\n",
    "# -------------------------------\n",
    "LOW_RISK = np.percentile(train_scores_norm, 75)\n",
    "MEDIUM_RISK = np.percentile(train_scores_norm, 90)\n",
    "HIGH_RISK = np.percentile(train_scores_norm, 97)\n",
    "\n",
    "def iso_risk_label(score):\n",
    "    if score >= HIGH_RISK:\n",
    "        return \"high\"\n",
    "    elif score >= MEDIUM_RISK:\n",
    "        return \"medium\"\n",
    "    elif score >= LOW_RISK:\n",
    "        return \"low\"\n",
    "    else:\n",
    "        return \"normal\"\n",
    "\n",
    "risk_labels_val = [iso_risk_label(s) for s in val_scores_norm]\n",
    "\n",
    "# -------------------------------\n",
    "# 9Ô∏è‚É£ Offline evaluation only\n",
    "# -------------------------------\n",
    "print(\"Isolation Forest ROC-AUC:\",\n",
    "      roc_auc_score(y_val, val_scores_norm))\n",
    "\n",
    "# -------------------------------\n",
    "# üîü Save artifacts for downstream layers\n",
    "# -------------------------------\n",
    "joblib.dump(iso, \"iso_forest_model.pkl\")\n",
    "joblib.dump(feature_scaler, \"iso_feature_scaler.pkl\")\n",
    "joblib.dump(score_scaler, \"iso_score_scaler.pkl\")\n",
    "joblib.dump(to_drop, \"iso_dropped_features.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd407ac-c51c-4de3-b42c-9dc791c8446c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
